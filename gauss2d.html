<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Inferring Gaussians with the Dirichlet Process Mixture Model</title>
    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootswatch-3.3.4/lumen/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.3.4/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="None" href="index.html" />
    <link rel="up" title="Tutorials" href="docs.html" />
    <link rel="next" title="Digit recognition with the MNIST dataset" href="mnist_predictions.html" />
    <link rel="prev" title="Univariate Data with the Normal Inverse Chi-Square Distribution" href="nic.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          datamicroscopes</a>
        <span class="navbar-text navbar-version pull-left"><b>0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="https://github.com/datamicroscopes">GitHub</a></li>
                <li><a href="https://qadium.com/">Qadium</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="intro.html">Discovering structure in your data: an overview of clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="enron_blog.html">Network Modeling with the Infinite Relational Model</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="datatypes.html">Datatypes and Bayesian Nonparametric Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="bb.html">Binary Data with the Beta Bernouli Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="dd.html">Categorical Data and the Dirichlet Discrete Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="niw.html">Real Valued Data and the Normal Inverse-Wishart Distribution</a></li>
<li class="toctree-l1"><a class="reference internal" href="nic.html">Univariate Data with the Normal Inverse Chi-Square Distribution</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="">Inferring Gaussians with the Dirichlet Process Mixture Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="mnist_predictions.html">Digit recognition with the MNIST dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="enron_email.html">Clustering the Enron e-mail corpus using the Infinite Relational Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="hdp.html">Learning Topics in The Daily Kos with the Hierarchical Dirichlet Process</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="docs.html">Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="intro.html">Discovering structure in your data: an overview of clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="enron_blog.html">Network Modeling with the Infinite Relational Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="docs.html#datatypes-and-likelihood-models-in-datamicroscopes">Datatypes and likelihood models in datamicroscopes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="datatypes.html">Datatypes and Bayesian Nonparametric Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="bb.html">Binary Data with the Beta Bernouli Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="dd.html">Categorical Data and the Dirichlet Discrete Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="niw.html">Real Valued Data and the Normal Inverse-Wishart Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="nic.html">Univariate Data with the Normal Inverse Chi-Square Distribution</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="docs.html#examples">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="">Inferring Gaussians with the Dirichlet Process Mixture Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="mnist_predictions.html">Digit recognition with the MNIST dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="enron_email.html">Clustering the Enron e-mail corpus using the Infinite Relational Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="hdp.html">Learning Topics in The Daily Kos with the Hierarchical Dirichlet Process</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="microscopes.common.dataview.html">dataviews</a></li>
<li class="toctree-l2"><a class="reference internal" href="microscopes.common.util.html">util</a></li>
<li class="toctree-l2"><a class="reference internal" href="microscopes.common.random.html">microscopes.common.random</a></li>
<li class="toctree-l2"><a class="reference internal" href="microscopes.common.query.html">query</a></li>
<li class="toctree-l2"><a class="reference internal" href="microscopes.common.validator.html">microscopes.common.validator</a></li>
<li class="toctree-l2"><a class="reference internal" href="microscopes.kernels.parallel.html">parallel</a></li>
<li class="toctree-l2"><a class="reference internal" href="microscopes.mixture.html">mixturemodel</a></li>
<li class="toctree-l2"><a class="reference internal" href="microscopes.irm.html">irm</a></li>
<li class="toctree-l2"><a class="reference internal" href="microscopes.kernels.html">kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="api.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Contents <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Inferring Gaussians with the Dirichlet Process Mixture Model</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/gauss2d.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12">
      
  <div class="section" id="inferring-gaussians-with-the-dirichlet-process-mixture-model">
<span id="gauss2d"></span><h1>Inferring Gaussians with the Dirichlet Process Mixture Model<a class="headerlink" href="#inferring-gaussians-with-the-dirichlet-process-mixture-model" title="Permalink to this headline">Â¶</a></h1>
<hr class="docutils" />
<p>Let&#8217;s set up our environment</p>
<div class="code python highlight-python"><div class="highlight"><pre>%matplotlib inline
import matplotlib.pylab as plt
import numpy as np
import time
import seaborn as sns
import pandas as pd
sns.set_style(&#39;darkgrid&#39;)
sns.set_context(&#39;talk&#39;)
sns.set_palette(&quot;Set2&quot;, 30)
</pre></div>
</div>
<p>Now let&#8217;s import our functions from datamicroscopes</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">microscopes.common.rng</span> <span class="kn">import</span> <span class="n">rng</span>
<span class="kn">from</span> <span class="nn">microscopes.common.recarray.dataview</span> <span class="kn">import</span> <span class="n">numpy_dataview</span>
<span class="kn">from</span> <span class="nn">microscopes.models</span> <span class="kn">import</span> <span class="n">niw</span> <span class="k">as</span> <span class="n">normal_inverse_wishart</span>
<span class="kn">from</span> <span class="nn">microscopes.mixture.definition</span> <span class="kn">import</span> <span class="n">model_definition</span>
<span class="kn">from</span> <span class="nn">microscopes.mixture</span> <span class="kn">import</span> <span class="n">model</span><span class="p">,</span> <span class="n">runner</span><span class="p">,</span> <span class="n">query</span>
<span class="kn">from</span> <span class="nn">microscopes.common.query</span> <span class="kn">import</span> <span class="n">zmatrix_heuristic_block_ordering</span><span class="p">,</span> <span class="n">zmatrix_reorder</span>
</pre></div>
</div>
<p>From here, we&#8217;ll generate four isotropic 2D gaussian clusters in each
quadrant, varying the scale parameter</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">nsamples_per_cluster</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">scales</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.08</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
<span class="n">Y_clusters</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
        <span class="n">mean</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span>
        <span class="n">cov</span><span class="o">=</span><span class="n">var</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
        <span class="n">size</span><span class="o">=</span><span class="n">nsamples_per_cluster</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">mu</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">scales</span><span class="p">)]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">Yc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">Y_clusters</span><span class="p">):</span>
    <span class="n">cl</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">Yc</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">,</span><span class="s">&#39;y&#39;</span><span class="p">])</span>
    <span class="n">cl</span><span class="p">[</span><span class="s">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cl</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">Y_clusters</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
      <th>y</th>
      <th>cluster</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.557005</td>
      <td>1.266202</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.465262</td>
      <td>0.842641</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.619352</td>
      <td>1.309368</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.130965</td>
      <td>0.700129</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.447409</td>
      <td>1.112726</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div><p>Let&#8217;s have a look at the generated data</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">sns</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span> <span class="s">&#39;y&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">&quot;cluster&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">fit_reg</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Simulated Gaussians: 4 Clusters&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>&lt;matplotlib.text.Text at 0x112cf7290&gt;
</pre></div>
</div>
<img alt="_images/gauss2d_8_1.png" src="_images/gauss2d_8_1.png" />
<p>Now let&#8217;s learn this clustering non-parametrically!</p>
<p>There are 5 steps necessary to set up your model:</p>
<ol class="arabic simple">
<li>Decide on the number of chains we want &#8211; it is important to run
multiple chains from different starting points!</li>
<li>Define our DP-GMM model</li>
<li>Munge the data into numpy recarray format then wrap the data for our
model</li>
<li>Randomize start points</li>
<li>Create runners for each chain</li>
</ol>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">nchains</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c"># The random state object</span>
<span class="n">prng</span> <span class="o">=</span> <span class="n">rng</span><span class="p">()</span>

<span class="c"># Define a DP-GMM where the Gaussian is 2D</span>
<span class="n">defn</span> <span class="o">=</span> <span class="n">model_definition</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">normal_inverse_wishart</span><span class="p">(</span><span class="mi">2</span><span class="p">)])</span>

<span class="c"># Munge the data into numpy recarray format</span>
<span class="n">Y_rec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">),)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[(</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="mi">2</span><span class="p">)])</span>

<span class="c"># Create a wrapper around the numpy recarray which</span>
<span class="c"># data-microscopes understands</span>
<span class="n">view</span> <span class="o">=</span> <span class="n">numpy_dataview</span><span class="p">(</span><span class="n">Y_rec</span><span class="p">)</span>

<span class="c"># Initialize nchains start points randomly in the state space</span>
<span class="n">latents</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">defn</span><span class="p">,</span> <span class="n">view</span><span class="p">,</span> <span class="n">prng</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">nchains</span><span class="p">)]</span>

<span class="c"># Create a runner for each chain</span>
<span class="n">runners</span> <span class="o">=</span> <span class="p">[</span><span class="n">runner</span><span class="o">.</span><span class="n">runner</span><span class="p">(</span><span class="n">defn</span><span class="p">,</span> <span class="n">view</span><span class="p">,</span> <span class="n">latent</span><span class="p">,</span> <span class="n">kernel_config</span><span class="o">=</span><span class="p">[</span><span class="s">&#39;assign&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">latent</span> <span class="ow">in</span> <span class="n">latents</span><span class="p">]</span>
</pre></div>
</div>
<p>We will visualize our data to examine the cluster assignment</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">plot_assignment</span><span class="p">(</span><span class="n">assignment</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">Y</span><span class="p">):</span>
    <span class="n">cl</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;x&#39;</span><span class="p">,</span><span class="s">&#39;y&#39;</span><span class="p">])</span>
    <span class="n">cl</span><span class="p">[</span><span class="s">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">assignment</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="n">cl</span><span class="p">[</span><span class="s">&#39;cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="s">&#39;x&#39;</span><span class="p">,</span> <span class="s">&#39;y&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">&quot;cluster&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">cl</span><span class="p">,</span> <span class="n">fit_reg</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">&lt;</span><span class="mi">10</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Simulated Gaussians: </span><span class="si">%d</span><span class="s"> Learned Clusters&#39;</span> <span class="o">%</span> <span class="n">n_clusters</span><span class="p">)</span>
</pre></div>
</div>
<p>Let&#8217;s peek at the starting state for one of our chains</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">plot_assignment</span><span class="p">(</span><span class="n">latents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">assignments</span><span class="p">())</span>
</pre></div>
</div>
<img alt="_images/gauss2d_14_0.png" src="_images/gauss2d_14_0.png" />
<p>Let&#8217;s watch one of the chains evolve for a few steps</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">first_runner</span> <span class="o">=</span> <span class="n">runners</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">first_runner</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="n">prng</span><span class="p">,</span> <span class="n">niters</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plot_assignment</span><span class="p">(</span><span class="n">first_runner</span><span class="o">.</span><span class="n">get_latent</span><span class="p">()</span><span class="o">.</span><span class="n">assignments</span><span class="p">())</span>
</pre></div>
</div>
<img alt="_images/gauss2d_16_0.png" src="_images/gauss2d_16_0.png" />
<img alt="_images/gauss2d_16_1.png" src="_images/gauss2d_16_1.png" />
<img alt="_images/gauss2d_16_2.png" src="_images/gauss2d_16_2.png" />
<img alt="_images/gauss2d_16_3.png" src="_images/gauss2d_16_3.png" />
<img alt="_images/gauss2d_16_4.png" src="_images/gauss2d_16_4.png" />
<p>Now let&#8217;s burn all our runners in for 100 iterations.</p>
<p>We&#8217;ll do this sequentially since the model is simple, but check
microscopes.parallel.runner for parallel implementions (with support for
either multiprocessing or multyvac)</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">runner</span> <span class="ow">in</span> <span class="n">runners</span><span class="p">:</span>
    <span class="n">runner</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="n">prng</span><span class="p">,</span> <span class="n">niters</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
<p>Let&#8217;s now peek again at the first state</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">plot_assignment</span><span class="p">(</span><span class="n">first_runner</span><span class="o">.</span><span class="n">get_latent</span><span class="p">()</span><span class="o">.</span><span class="n">assignments</span><span class="p">())</span>
</pre></div>
</div>
<img alt="_images/gauss2d_20_0.png" src="_images/gauss2d_20_0.png" />
<p>Let&#8217;s build a z-matrix to compare our result with the rest of the chains</p>
<p>We&#8217;ll be sure to sort our z-matrix before plotting. Sorting the
datapoints allows us to organize the clusters into a block matrix.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">infers</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="o">.</span><span class="n">get_latent</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">runners</span><span class="p">]</span>
<span class="n">zmat</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">zmatrix</span><span class="p">(</span><span class="n">infers</span><span class="p">)</span>
<span class="n">ordering</span> <span class="o">=</span> <span class="n">zmatrix_heuristic_block_ordering</span><span class="p">(</span><span class="n">zmat</span><span class="p">)</span>
<span class="n">zmat</span> <span class="o">=</span> <span class="n">zmatrix_reorder</span><span class="p">(</span><span class="n">zmat</span><span class="p">,</span> <span class="n">ordering</span><span class="p">)</span>
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">zmat</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;entities (sorted)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;entities (sorted)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Z-matrix of Cluster Assignments&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>&lt;matplotlib.text.Text at 0x116f73510&gt;
</pre></div>
</div>
<img alt="_images/gauss2d_23_1.png" src="_images/gauss2d_23_1.png" />
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2015, Qadium.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>